{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02181667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\U1024363\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\U1024363\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 next-word predictions for 'the united':\n",
      "['states', 'nations', \"states'\", \"nations'\", 'kingdom']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Step 1: Download and load the corpus\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Remove punctuation and lowercase the words\n",
    "def preprocess_brown():\n",
    "    words = brown.words()\n",
    "    words = [word.lower() for word in words if word not in string.punctuation]\n",
    "    return words\n",
    "\n",
    "# Step 2: Generate n-grams and return as DataFrame with frequencies\n",
    "def get_ngrams_freq(words, n):\n",
    "    n_grams = list(ngrams(words, n))\n",
    "    ngram_freq = Counter(n_grams)\n",
    "    df = pd.DataFrame(ngram_freq.items(), columns=['ngram', 'frequency'])\n",
    "    df = df.sort_values(by='frequency', ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Step 3: Predict next words using n-gram model\n",
    "def predict_next_word(words, ngram_df, input_seq, n, k):\n",
    "    \"\"\"\n",
    "    input_seq: sequence of (n-1) words (as a string), e.g. 'the dog'\n",
    "    n: size of n-gram model\n",
    "    k: number of predictions\n",
    "    \"\"\"\n",
    "    tokens = input_seq.lower().split()\n",
    "    if len(tokens) != n - 1:\n",
    "        raise ValueError(f\"Expected {n-1} words for {n}-gram model, but got {len(tokens)}.\")\n",
    "\n",
    "    # Filter n-grams that start with the input sequence\n",
    "    filtered = ngram_df[ngram_df['ngram'].apply(lambda x: x[:-1] == tuple(tokens))]\n",
    "    \n",
    "    # Get top-k most frequent next words\n",
    "    top_k = filtered.sort_values(by='frequency', ascending=False).head(k)\n",
    "    predictions = top_k['ngram'].apply(lambda x: x[-1]).tolist()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Preprocess and generate data\n",
    "    tokens = preprocess_brown()\n",
    "    n = 3  # for trigram model\n",
    "    ngram_df = get_ngrams_freq(tokens, n)\n",
    "\n",
    "    # Predict next word\n",
    "    input_seq = \"the united\"\n",
    "    k = 5\n",
    "    predictions = predict_next_word(tokens, ngram_df, input_seq, n, k)\n",
    "    \n",
    "    print(f\"Top {k} next-word predictions for '{input_seq}':\")\n",
    "    print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9181c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
